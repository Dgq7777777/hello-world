# hello-world
just another repository
Hi,i don't kown if I'll make it.
hahah


主要:正则 (e)grep awk sed
了解:通用字符 扩展字符


感觉核心:
输入-处理-输出
1输入:
1.1指令中生成1.2文本中
2处理:
2.1定位到行，列感觉大致够用
2.2多行
2.3灵活运用 哈哈
3输出
输出主要就是一串字符吧，现在暂时这么理解

学习方法:
是通过常用的样本，加深记忆，以后有问题，记不清，看看样本
运用中将基础灵活运用
再在实践中对较偏的知识点，覆盖



第一个 来吧!
df –Th  //磁盘指令
echo `df -Th |grep '/$'`  //这里定位到了行,grep后默认的是正则表达式模式. 过滤以/结尾
echo `df –Th |grep ‘/$’ |awk {print $(NF-1)}  //awk 取倒数第二个参数
`df -Th |grep '/$'|gawk '{print $(NF-1)}' | gawk -F"%" '{print $1}'` //两次awk 终于抱得美人归

问题-------错的时间，错的地点，美丽的遇见
1.	echo `df -Th |grep '\$'`  这里打错  一行的形式输出
2.	echo `df –Th |grep ‘/$’ |awk -F {print $(NF-1)} 没事不要用分隔符-F  又不改
-F”%”   没有：别多想
3.	(按列)awk中NF为最后一个分隔符号的位置数字
4.  
"11 22 33 44" > |awk '{print $3}'  对字符串的
`"11 22 33 44" |awk '{print $3}'`
单纯这么是不行的！重定向也不行，都是输出,为什么不行！
只能曲线救国…字符串使用正则
echo `echo "11 22 33 44" |awk '{print $3}'`
有意思

第二个
awk -F"-" '/test/{print $1}' saveloglist.txt   单纯正则字符，表示含有即可/test/
从文件中读取某些特征的行，再分隔取列。
num=3
gawk -F"-" '/-test-"$num"/{print $(NF-1)}' saveloglist.txt
变量不好用

以什么开始^放在探测变量的前面
df -Th |awk '/^\//{print $0}'   带有特殊符号的检测，需要先转义一下，不知不觉就被坑了有点意思

df -Th |awk '/\/$/{print $0}'|awk '{print $(NF-1)}'|awk -F"%" '{print $1}'
disk_use=`df -Th |grep '/$' |awk '{print $(NF-1)}' |awk -F"%" '{print $1}'`  实现同样的功能

df -Th |awk '/^tmp$/{print $0}'    错误的原因，是因为无法锚定开头的和结尾的界限
df -Th |awk '/^tm.*p$/{print $0}     成功。可以看出各类特殊符号(元字符)起着自然分割，划定界限的作用

打印确定的某一行……
1.1df -Th |awk 'NR==1{print $0}'  
1.2引出NR与FNR
NR,表示awk开始执行程序后所读取的数据行数.
FNR,与NR功用类似,不同的是awk每打开一个新文件,FNR便从0重新累计.
结束的时候，统计行数
df –Th | awk ‘END{print $0}’
1.3回去
df -Th |awk 'NR==1{print $0}' 的实质 df -Th |awk '{if(NR==1) {print $0}}'

1.4计算  终于知道 为什么有-h这个选项了  有了
-h 确实容易读，高可读性  没有高可读性，才方便计算
awk '{if(NR!=1){print $3}}'|awk '{a+=$0} END{printf("%d"),a}' 正确，printf()可以用
df -T |awk '{if(NR!=1){print $3}}'|awk '{a+=$0} END{print $a}'   荒诞不经 为什么不行
df -T |awk '{if(NR!=1){print $3}}'|awk '{a+=$0} END{print a}'   因为 a=是变量
df -T |awk '{if(NR!=1){print $3}}'|awk '{a+=$0} END{ecoh a}'   C语言领域


1.5
#cat account1
张三|000001
李四|000002
#cat cdr1
000001|10
000001|20
000002|30
000002|15
想要得到的结果是将用户名，帐号和金额在同一行打印出来,如下:

张三|000001|10
张三|000001|20
李四|000002|30
李四|000002|15
awk -F \| 'NR==FNR{a[$2]=$0;next}{print a[$1]"|"$2}' account1 cdr1  合并的运用，呵呵还真行…
其中的next起着跳过的功能，跳过后面的操作,就不执行{print a[$1]"|"$2}
应该是按顺序读！两个文件
由NR=FNR为真时,判断当前读入的是第一个文件account,然后使用{a[$2]=$0;next}循环将account文件的每行记录都存入数组a,并使用$2第2个字段作为下标引用.
由NR=FNR为假时,判断当前读入了第二个文件cdr,然后跳过{a[$2]=$0;next},对第二个文件cdr的每一行都无条件执行{print a[$1]"|"$2},此时变量$1为第二个文件的第一个字段,与读入第一个文件时,采用第一个文件第二个字段$2为数组下标相同.因此可以在此使用a[$1]引用数组。

第三个 基本的都能切了，最后对字符串的切割


 
正则主要分为基础正则表达式(BRE)引擎，扩展表达式(PRE)引擎
ERE主要出现在依赖RE的语言中，如提供匹配数字，单词和按字母排序的字符。
gawk使用ERE引擎处理他们的正则表达式.

来看看常用的模式，元字符
BRE引擎
常用
^(后面的字符)以什么开始 $(前面的字符)以什么结束
.匹配单个字符   .*匹配不限数量的字符   *(前面)出现0到多次 +(前面)1到多次

[ ] 表达式的开始和结束范围内的 
1.表示在某个区间内[a-Z0-9] 
2.在某几个的范围内[12345]
3.[^]取反操作
4.[.   *]去掉其特殊性
() 子表达式的开始和结束()里的东西看成整体        |几个选项中的一个都行 或
{ } 限定符表达式 出现的次数
ab{1,3},就表示a，后面紧跟的b出现最少1次，最多3次
(ab){1,3}，就表示ab一起连续出现最少1次，最多3次
[ab]{1,2},表示aa|ab|ba|bb等这几种情况


限定符号前面的必须出现次数
*{0,}，+{1,}，?{0,1}
{}  {1} {1,} {1,5}(前面的字符出现多少次)
*,+都是贪婪匹配尽可能多的匹配  技巧：加上一个?实现最小匹配

定位符号
^ $ 对行
\b(单词边界)  \B(对非单词边界)
\b 字符的位置是非常重要的。如果它位于要匹配的字符串的开始，它在单词的开始处查找匹配项。如果它位于字符串的结尾，它在单词的结尾处查找匹配项
\B    /\Bapt/ 只能匹配 Chapter 中的字符串 apt，但不匹配 aptitude 中的字符串 apt

选择(适合东想一下，西想一下的情况)
用圆括号将所有选择项括起来，相邻的选择项之间用|分隔。但用圆括号会有一个副作用，使相关的匹配会被缓存，此时可用?:放在第一个选项前来消除这种副作用。
其中 ?: 是非捕获元之一，还有两个非捕获元是 ?= 和 ?!，这两个还有更多的含义，前者为正向预查，在任何开始匹配圆括号内的正则表达式模式的位置来匹配搜索字符串，后者为负向预查，在任何开始不匹配该正则表达式模式的位置来匹配搜索字符串。

//我和我最后的倔强
